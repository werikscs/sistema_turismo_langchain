{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13012a3f",
   "metadata": {},
   "source": [
    "# Projeto de Turismo com LangChain - Passo 1: Ingestão de Dados\n",
    "\n",
    "Este notebook é responsável por preparar e enviar nossa base de conhecimento para o Pinecone. O processo consiste em:\n",
    "1. Carregar as chaves de API.\n",
    "2. Ler os arquivos de texto da pasta `/data`.\n",
    "3. Dividir os textos em \"chunks\" (pedaços).\n",
    "4. Gerar \"embeddings\" (vetores numéricos) para cada chunk.\n",
    "5. Criar um índice no Pinecone (se não existir) e enviar os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5243d221",
   "metadata": {},
   "source": [
    "## 0. Pré-requisitos\n",
    "\n",
    "Certifique-se de que as bibliotecas necessárias estão instaladas. Se não estiverem, execute a célula abaixo (removendo o `#` inicial)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec11e933",
   "metadata": {},
   "source": [
    "# !pip install langchain langchain-community langchain-groq langchain-pinecone pinecone-client python-dotenv sentence-transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e71c6f",
   "metadata": {},
   "source": [
    "## 1. Carregar Bibliotecas e Variáveis de Ambiente\n",
    "\n",
    "Primeiro, importamos todas as ferramentas que vamos usar e carregamos nossas chaves secretas do arquivo `.env`. É fundamental que o arquivo `.env` esteja na mesma pasta que este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be49c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weriks/anaconda3/envs/sistema_turismo_langchain/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis de ambiente carregadas com sucesso!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weriks/anaconda3/envs/sistema_turismo_langchain/lib/python3.13/site-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Carrega as variáveis do arquivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Pega as variáveis do ambiente\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "index_name = os.getenv(\"PINECONE_INDEX_NAME\")\n",
    "\n",
    "# Verificação de segurança\n",
    "if not pinecone_api_key or not index_name:\n",
    "    print(\"Erro: Verifique se as variáveis PINECONE_API_KEY e PINECONE_INDEX_NAME estão no arquivo .env\")\n",
    "else:\n",
    "    print(\"Variáveis de ambiente carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2800cfbb",
   "metadata": {},
   "source": [
    "## 2. Carregar os Documentos da Pasta `/data`\n",
    "\n",
    "Agora, vamos usar o `DirectoryLoader` do LangChain para encontrar e carregar todos os arquivos `.txt` que estão na nossa pasta de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "995348cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Carregando documentos da pasta /data ---\n",
      "Carregados 2 documentos.\n",
      " \n",
      "# Informações Gerais sobre Paris, França\n",
      "\n",
      "Paris, a capital da França, é um centro global de arte, moda, gastronomia e cultura. Conhecida como a \"Cidade Luz\", é famosa por seus monumentos icônicos, museus de classe mundial, charmosos cafés e alta costura. O rio Sena corta a cidade, e suas margens são repletas de pontos de interesse.\n",
      "\n",
      "## Principais Pontos Turísticos\n",
      "\n",
      "### Torre Eiffel\n",
      "- **Descrição:** O monumento mais emblemático de Paris, construído por Gustave Eiffel para a Exposição Universal \n"
     ]
    }
   ],
   "source": [
    "print(\"--- Carregando documentos da pasta /data ---\")\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data/\",\n",
    "    glob=\"*.txt\",  # Padrão para buscar apenas arquivos .txt\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Carregados {len(documents)} documentos.\")\n",
    "# Para inspecionar um documento, você pode descomentar a linha abaixo:\n",
    "print(documents[0].page_content[:500]) # Mostra os primeiros 500 caracteres do primeiro documento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70acdc6e",
   "metadata": {},
   "source": [
    "## 3. Dividir os Documentos em Chunks\n",
    "\n",
    "Documentos longos são ineficientes para buscas de similaridade. Por isso, nós os quebramos em pedaços menores (chunks). O `RecursiveCharacterTextSplitter` é inteligente e tenta manter parágrafos e sentenças coesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae4b43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dividindo os documentos em chunks ---\n",
      "Documentos divididos em 11 chunks.\n",
      "\n",
      "--- Exemplo de Chunk ---\n",
      "# Informações Gerais sobre o Rio de Janeiro, Brasil\n",
      "\n",
      "O Rio de Janeiro, conhecido como a \"Cidade Maravilhosa\", é um dos principais destinos turísticos do Brasil. É famoso mundialmente por suas praias deslumbrantes como Copacabana e Ipanema, a estátua do Cristo Redentor no topo do Corcovado, o Pão de Açúcar e o animado Carnaval. A cidade oferece uma mistura única de metrópole urbana e natureza exuberante, com montanhas e florestas tropicais em meio à paisagem urbana.\n",
      "\n",
      "## Principais Pontos Turísticos\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Dividindo os documentos em chunks ---\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Tamanho máximo de cada chunk em caracteres\n",
    "    chunk_overlap=200,  # Sobreposição entre chunks para não perder o contexto\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs_split = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Documentos divididos em {len(docs_split)} chunks.\")\n",
    "# Para inspecionar um chunk, você pode descomentar a linha abaixo:\n",
    "print(\"\\n--- Exemplo de Chunk ---\")\n",
    "print(docs_split[5].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649da6a6",
   "metadata": {},
   "source": [
    "## 4. Inicializar o Modelo de Embeddings\n",
    "\n",
    "A \"mágica\" do RAG acontece aqui. Um modelo de embedding transforma o texto de cada chunk em um vetor (uma lista de números). Textos com significados parecidos terão vetores próximos no espaço vetorial. Usaremos um modelo gratuito e de alta performance da Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13fb95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_376653/3296105770.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Inicializando o modelo de embeddings ---\n",
      "Aguarde, isso pode levar um tempo para baixar o modelo na primeira execução...\n",
      "\n",
      "Modelo de embeddings inicializado.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Inicializando o modelo de embeddings ---\")\n",
    "print(\"Aguarde, isso pode levar um tempo para baixar o modelo na primeira execução...\")\n",
    "\n",
    "# Modelo popular e com bom desempenho\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\" \n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "# O modelo 'all-MiniLM-L6-v2' gera vetores de dimensão 384.\n",
    "# Guardamos este valor, pois é essencial para criar o índice no Pinecone.\n",
    "embedding_dimension = 384\n",
    "\n",
    "print(\"\\nModelo de embeddings inicializado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8bab0",
   "metadata": {},
   "source": [
    "## 5. Conectar e Configurar o Pinecone\n",
    "\n",
    "Com os dados prontos e o modelo de embedding carregado, vamos preparar nossa base de dados vetorial. O código abaixo se conecta ao Pinecone e verifica se o nosso índice já existe. Se não existir, ele o cria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e72ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Conectando ao Pinecone e preparando o índice 'sistema-turismo' ---\n",
      "Índice 'sistema-turismo' já existe. Conectando...\n"
     ]
    }
   ],
   "source": [
    "print(f\"--- Conectando ao Pinecone e preparando o índice '{index_name}' ---\")\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "# Verifica se o índice já existe\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    print(f\"Índice '{index_name}' não encontrado. Criando um novo...\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=embedding_dimension, # A dimensão DEVE ser a mesma do modelo de embedding\n",
    "        metric=\"cosine\", # Métrica de similaridade ideal para texto\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1' # Região padrão e gratuita\n",
    "        ) \n",
    "    )\n",
    "    # Aguarda um momento para o índice ficar pronto\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        print(\"Aguardando o índice ficar pronto...\")\n",
    "        time.sleep(1)\n",
    "    print(\"Índice criado com sucesso!\")\n",
    "else:\n",
    "    print(f\"Índice '{index_name}' já existe. Conectando...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ece1e4",
   "metadata": {},
   "source": [
    "## 6. Ingerir os Dados no Pinecone\n",
    "\n",
    "Este é o passo final. A função `from_documents` do LangChain irá, para cada chunk:\n",
    "1. Gerar o embedding usando o modelo que carregamos.\n",
    "2. Enviar o chunk e seu embedding correspondente para o índice do Pinecone.\n",
    "\n",
    "Este processo pode demorar alguns minutos, dependendo da quantidade de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a8da89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando a ingestão dos documentos no Pinecone ---\n",
      "\n",
      "--- Ingestão de dados concluída com sucesso! ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando a ingestão dos documentos no Pinecone ---\")\n",
    "\n",
    "PineconeVectorStore.from_documents(\n",
    "    documents=docs_split,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "print(\"\\n--- Ingestão de dados concluída com sucesso! ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d141011",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Pronto! Se todas as células foram executadas com sucesso, seu índice no Pinecone agora contém o conhecimento sobre o Rio de Janeiro e Paris. O próximo passo é construir as cadeias (Chains) que irão consultar esses dados para responder às perguntas dos usuários."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sistema_turismo_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
